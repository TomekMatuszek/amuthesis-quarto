
@techreport{witjes_spatiotemporal_2021,
	type = {preprint},
	title = {A spatiotemporal ensemble machine learning framework for generating land use / land cover time-series maps for {Europe} (2000 – 2019) based on {LUCAS}, {CORINE} and {GLAD} {Landsat}},
	url = {https://www.researchsquare.com/article/rs-561383/v1},
	abstract = {Abstract
          A seamless spatiotemporal machine learning framework for automated prediction, uncertainty assessment, and analysis of land use / land cover (LULC) dynamics is presented. The framework includes: (1) harmonization and preprocessing of high-resolution spatial and spatiotemporal covariate datasets (GLAD Landsat, NPP/VIIRS) including 5 million harmonized LUCAS and CORINE Land Cover-derived training samples, (2) model building based on spatial k-fold cross-validation and hyper-parameter optimization, (3) prediction of the most probable class, class probabilities and uncertainty per pixel, (4) LULC change analysis on time-series of produced maps. The spatiotemporal ensemble model was fitted by combining random forest, gradient boosted trees, and artificial neural network, with logistic regressor as meta-learner. The results show that the most important covariates for mapping LULC in Europe are: seasonal aggregates of Landsat green and near-infrared bands, multiple Landsat-derived spectral indices, and elevation. Spatial cross-validation of the model indicates consistent performance across multiple years with 62\%, 70\%, and 87\% accuracy when predicting 33 (level-3), 14 (level-2), and 5 classes (level-1); with artificial surface classes such as 'airports' and 'railroads' showing the lowest match with validation points. The spatiotemporal model outperforms spatial models on known-year classification by 2.7\% and unknown-year classification by 3.5\%. Results of the accuracy assessment using 48,365 independent test samples shows 87\% match with the validation points. Results of time-series analysis (time-series of LULC probabilities and NDVI images) suggest gradual deforestation trends in large parts of Sweden, the Alps, and Scotland. An advantage of using spatiotemporal ML is that the fitted model can be used to predict LULC in years that were not included in its training dataset, allowing generalization to past and future periods, e.g. to predict land cover for years prior to 2000 and beyond 2020. The generated land cover time-series data stack (ODSE-LULC), including the training points, is publicly available via the Open Data Science (ODS)-Europe Viewer.},
	language = {en},
	urldate = {2022-04-07},
	institution = {In Review},
	author = {Witjes, Martijn and Parente, Leandro and Diemen, Chris J. van and Hengl, Tomislav and Landa, Martin and Brodsky, Lukas and Halounova, Lena and Krizan, Josip and Antonic, Luka and Ilie, Codrina M and Craciunescu, Vasile and Kilibarda, Milan and Antonijevic, Ognjen and Glusica, Luka},
	month = may,
	year = {2021},
	doi = {10.21203/rs.3.rs-561383/v1},
	file = {Witjes et al. - 2021 - A spatiotemporal ensemble machine learning framewo.pdf:C\:\\Users\\Tomek\\Zotero\\storage\\STFWEGZT\\Witjes et al. - 2021 - A spatiotemporal ensemble machine learning framewo.pdf:application/pdf},
}

@book{european_environment_agency_thematic_2006,
	address = {Luxembourg},
	title = {The thematic accuracy of {Corine} land cover 2000: assessment using {LUCAS} (land use/cover area frame statistical survey).},
	isbn = {978-92-9167-844-0},
	shorttitle = {The thematic accuracy of {Corine} land cover 2000},
	url = {http://bookshop.europa.eu/uri?target=EUB:NOTICE:THAK06006:EN:HTML},
	abstract = {The purpose of this report is to assess the thematic accuracy of CLC2000 by means of an independent data source, the LUCAS data (not used in the compilation of the target database - CLC2000) and statistical methods homogeneously applied to as many of the participating countries as possible. The purpose of validating geographical data is to derive final accuracy/reliability figures by means of independent, high resolution and more accurate data, which is related to a similar data acquisition period.},
	language = {en},
	urldate = {2022-04-07},
	publisher = {Publications Office},
	author = {{European Environment Agency}},
	year = {2006},
	note = {OCLC: 904337694},
	file = {European Environment Agency - 2006 - The thematic accuracy of Corine land cover 2000 a.pdf:C\:\\Users\\Tomek\\Zotero\\storage\\KJJC9M92\\European Environment Agency - 2006 - The thematic accuracy of Corine land cover 2000 a.pdf:application/pdf},
}

@article{malinowski_automated_2020,
	title = {Automated {Production} of a {Land} {Cover}/{Use} {Map} of {Europe} {Based} on {Sentinel}-2 {Imagery}},
	volume = {12},
	issn = {2072-4292},
	url = {https://www.mdpi.com/2072-4292/12/21/3523},
	doi = {10.3390/rs12213523},
	abstract = {Up-to-date information about the Earth’s surface provided by land cover maps is essential for numerous environmental and land management applications. There is, therefore, a clear need for the continuous and reliable monitoring of land cover and land cover changes. The growing availability of high resolution, regularly collected remote sensing data can support the increasing number of applications that require high spatial resolution products that are frequently updated (e.g., annually). However, large-scale operational mapping requires a highly-automated data processing workﬂow, which is currently lacking. To address this issue, we developed a methodology for the automated classiﬁcation of multi-temporal Sentinel-2 imagery. The method uses a random forest classiﬁer and existing land cover/use databases as the source of training samples. In order to demonstrate its operability, the method was implemented on a large part of the European continent, with CORINE Land Cover and High-Resolution Layers as training datasets. A land cover/use map for the year 2017 was produced, composed of 13 classes. An accuracy assessment, based on nearly 52,000 samples, revealed high thematic overall accuracy (86.1\%) on a continental scale, and average overall accuracy of 86.5\% at country level. Only low-frequency classes obtained lower accuracies and we recommend that their mapping should be improved in the future. Additional modiﬁcations to the classiﬁcation legend, notably the fusion of thematically and spectrally similar vegetation classes, increased overall accuracy to 89.0\%, and resulted in ten, general classes. A crucial aspect of the presented approach is that it embraces all of the most important elements of Earth observation data processing, enabling accurate and detailed (10 m spatial resolution) mapping with no manual user involvement. The presented methodology demonstrates possibility for frequent and repetitive operational production of large-scale land cover maps.},
	language = {en},
	number = {21},
	urldate = {2022-04-07},
	journal = {Remote Sensing},
	author = {Malinowski, Radek and Lewiński, Stanisław and Rybicki, Marcin and Gromny, Ewa and Jenerowicz, Małgorzata and Krupiński, Michał and Nowakowski, Artur and Wojtkowski, Cezary and Krupiński, Marcin and Krätzschmar, Elke and Schauer, Peter},
	month = oct,
	year = {2020},
	pages = {3523},
	file = {Malinowski et al. - 2020 - Automated Production of a Land CoverUse Map of Eu.pdf:C\:\\Users\\Tomek\\Zotero\\storage\\XZNLT9D2\\Malinowski et al. - 2020 - Automated Production of a Land CoverUse Map of Eu.pdf:application/pdf},
}

@article{potapov_landsat_2020,
	title = {Landsat {Analysis} {Ready} {Data} for {Global} {Land} {Cover} and {Land} {Cover} {Change} {Mapping}},
	volume = {12},
	issn = {2072-4292},
	url = {https://www.mdpi.com/2072-4292/12/3/426},
	doi = {10.3390/rs12030426},
	abstract = {The multi-decadal Landsat data record is a unique tool for global land cover and land use change analysis. However, the large volume of the Landsat image archive and inconsistent coverage of clear-sky observations hamper land cover monitoring at large geographic extent. Here, we present a consistently processed and temporally aggregated Landsat Analysis Ready Data produced by the Global Land Analysis and Discovery team at the University of Maryland (GLAD ARD) suitable for national to global empirical land cover mapping and change detection. The GLAD ARD represent a 16-day time-series of tiled Landsat normalized surface reﬂectance from 1997 to present, updated annually, and designed for land cover monitoring at global to local scales. A set of tools for multi-temporal data processing and characterization using machine learning provided with GLAD ARD serves as an end-to-end solution for Landsat-based natural resource assessment and monitoring. The GLAD ARD data and tools have been implemented at the national, regional, and global extent for water, forest, and crop mapping. The GLAD ARD data and tools are available at the GLAD website for free access.},
	language = {en},
	number = {3},
	urldate = {2022-04-07},
	journal = {Remote Sensing},
	author = {Potapov, Peter and Hansen, Matthew C. and Kommareddy, Indrani and Kommareddy, Anil and Turubanova, Svetlana and Pickens, Amy and Adusei, Bernard and Tyukavina, Alexandra and Ying, Qing},
	month = jan,
	year = {2020},
	pages = {426},
	file = {Potapov et al. - 2020 - Landsat Analysis Ready Data for Global Land Cover .pdf:C\:\\Users\\Tomek\\Zotero\\storage\\SI69B67B\\Potapov et al. - 2020 - Landsat Analysis Ready Data for Global Land Cover .pdf:application/pdf},
}

@article{varga_validation_2021,
	title = {Validation of {Visually} {Interpreted} {Corine} {Land} {Cover} {Classes} with {Spectral} {Values} of {Satellite} {Images} and {Machine} {Learning}},
	volume = {13},
	issn = {2072-4292},
	url = {https://www.mdpi.com/2072-4292/13/5/857},
	doi = {10.3390/rs13050857},
	abstract = {We analyzed the Corine Land Cover 2018 (CLC2018) dataset to reveal the correspondence between land cover categories of the CLC and the spectral information of Landsat-8, Sentinel-2 and PlanetScope images. Level 1 categories of the CLC2018 were analyzed in a 25 km × 25 km study area in Hungary. Spectral data were summarized by land cover polygons, and the dataset was evaluated with statistical tests. We then performed Linear Discriminant Analysis (LDA) and Random Forest classiﬁcations to reveal if CLC L1 level categories were conﬁrmed by spectral values. Wetlands and water bodies were the most likely to be confused with other categories. The least mixture was observed when we applied the median to quantify the pixel variance of CLC polygons. RF outperformed the LDA’s accuracy, and PlanetScope’s data were the most accurate. Analysis of class level accuracies showed that agricultural areas and wetlands had the most issues with misclassiﬁcation. We proved the representativeness of the results with a repeated randomized test, and only PlanetScope seemed to be ungeneralizable. Results showed that CLC polygons, as basic units of land cover, can ensure 71.1–78.5\% OAs for the three satellite sensors; higher geometric resolution resulted in better accuracy. These results justiﬁed CLC polygons, in spite of visual interpretation, can hold relevant information about land cover considering the surface reﬂectance values of satellites. However, using CLC as ground truth data for land cover classiﬁcations can be questionable, at least in the L1 nomenclature.},
	language = {en},
	number = {5},
	urldate = {2022-04-07},
	journal = {Remote Sensing},
	author = {Varga, Orsolya Gyöngyi and Kovács, Zoltán and Bekő, László and Burai, Péter and Csatáriné Szabó, Zsuzsanna and Holb, Imre and Ninsawat, Sarawut and Szabó, Szilárd},
	month = feb,
	year = {2021},
	pages = {857},
	file = {Varga et al. - 2021 - Validation of Visually Interpreted Corine Land Cov.pdf:C\:\\Users\\Tomek\\Zotero\\storage\\H6UZPTDH\\Varga et al. - 2021 - Validation of Visually Interpreted Corine Land Cov.pdf:application/pdf},
}

@article{sun_improvement_2015,
	title = {The {Improvement} of {Land} {Cover} {Classification} by {Thermal} {Remote} {Sensing}},
	volume = {7},
	issn = {2072-4292},
	url = {http://www.mdpi.com/2072-4292/7/7/8368},
	doi = {10.3390/rs70708368},
	abstract = {Land cover classification has been widely investigated in remote sensing for agricultural, ecological and hydrological applications. Landsat images with multispectral bands are commonly used to study the numerous classification methods in order to improve the classification accuracy. Thermal remote sensing provides valuable information to investigate the effectiveness of the thermal bands in extracting land cover patterns. k-NN and Random Forest algorithms were applied to both the single Landsat 8 image and the time series Landsat 4/5 images for the Attert catchment in the Grand Duchy of Luxembourg, trained and validated by the ground-truth reference data considering the three level classification scheme from COoRdination of INformation on the Environment (CORINE) using the 10-fold cross validation method. The accuracy assessment showed that compared to the visible and near infrared (VIS/NIR) bands, the time series of thermal images alone can produce comparatively reliable land cover maps with the best overall accuracy of 98.7\% to 99.1\% for Level 1 classification and 93.9\% to 96.3\% for the Level 2 classification. In addition, the combination with the thermal band improves the overall accuracy by 5\% and 6\% for the single Landsat 8 image in Level 2 and Level 3 category and provides the best classified results with all seven bands for the time series of Landsat TM images.},
	language = {en},
	number = {7},
	urldate = {2022-04-07},
	journal = {Remote Sensing},
	author = {Sun, Liya and Schulz, Karsten},
	month = jun,
	year = {2015},
	pages = {8368--8390},
	file = {Sun i Schulz - 2015 - The Improvement of Land Cover Classification by Th.pdf:C\:\\Users\\Tomek\\Zotero\\storage\\D62T8WTL\\Sun i Schulz - 2015 - The Improvement of Land Cover Classification by Th.pdf:application/pdf},
}

@article{zhao_exploring_2019,
	title = {Exploring the addition of {Landsat} 8 thermal band in land-cover mapping},
	volume = {40},
	issn = {0143-1161, 1366-5901},
	url = {https://www.tandfonline.com/doi/full/10.1080/01431161.2019.1569281},
	doi = {10.1080/01431161.2019.1569281},
	abstract = {One focus of remote-sensing studies is obtaining highly accurate land-cover maps, which is essential for quantifying and monitoring changes in the environment. However, thermal data, which can provide auxiliary information, is often ignored in land-cover classiﬁcation. In this study we compare the performance of diﬀerent remote-sensing feature combinations with and without the Landsat 8 thermal band (band 10). The results show that overall the thermal feature had a positive eﬀect on mapping land cover. A combination of spectral features, indices and the thermal feature maximized the improvement in accuracy. The proposed classiﬁer was applied to map land cover in an area in Egypt. The thermal feature signiﬁcantly reduced the confusion between cropland and wetland. The improvement in accuracy obtained by adding the thermal feature was analysed in a time series spanning 1 year. We found that the thermal feature improved the classiﬁcation accuracy when temperature variations occurred among the diﬀerent land-cover types. The eﬀect of the thermal feature was also inﬂuenced by the land cover; in cloudless conditions, warmer weather can enhance the accuracy improvement of the thermal feature.},
	language = {en},
	number = {12},
	urldate = {2022-04-07},
	journal = {International Journal of Remote Sensing},
	author = {Zhao, Jiyao and Yu, Le and Xu, Yidi and Ren, Huazhong and Huang, Xiaomeng and Gong, Peng},
	month = jun,
	year = {2019},
	pages = {4544--4559},
	file = {Zhao et al. - 2019 - Exploring the addition of Landsat 8 thermal band i.pdf:C\:\\Users\\Tomek\\Zotero\\storage\\GX98THI4\\Zhao et al. - 2019 - Exploring the addition of Landsat 8 thermal band i.pdf:application/pdf},
}

@article{rwanga_accuracy_2017,
	title = {Accuracy {Assessment} of {Land} {Use}/{Land} {Cover} {Classification} {Using} {Remote} {Sensing} and {GIS}},
	volume = {08},
	issn = {2156-8359, 2156-8367},
	url = {http://www.scirp.org/journal/doi.aspx?DOI=10.4236/ijg.2017.84033},
	doi = {10.4236/ijg.2017.84033},
	abstract = {Remote sensing is one of the tool which is very important for the production of Land use and land cover maps through a process called image classification. For the image classification process to be successfully, several factors should be considered including availability of quality Landsat imagery and secondary data, a precise classification process and user’s experiences and expertise of the procedures. The objective of this research was to classify and map land-use/land-cover of the study area using remote sensing and Geospatial Information System (GIS) techniques. This research includes two sections (1) Landuse/Landcover (LULC) classification and (2) accuracy assessment. In this study supervised classification was performed using Non Parametric Rule. The major LULC classified were agriculture (65.0\%), water body (4.0\%), and built up areas (18.3\%), mixed forest (5.2\%), shrubs (7.0\%), and Barren/bare land (0.5\%). The study had an overall classification accuracy of 81.7\% and kappa coefficient (K) of 0.722. The kappa coefficient is rated as substantial and hence the classified image found to be fit for further research. This study present essential source of information whereby planners and decision makers can use to sustainably plan the environment.},
	language = {en},
	number = {04},
	urldate = {2022-04-07},
	journal = {International Journal of Geosciences},
	author = {Rwanga, Sophia S. and Ndambuki, J. M.},
	year = {2017},
	pages = {611--622},
	file = {Rwanga i Ndambuki - 2017 - Accuracy Assessment of Land UseLand Cover Classif.pdf:C\:\\Users\\Tomek\\Zotero\\storage\\WPJ3Z8UT\\Rwanga i Ndambuki - 2017 - Accuracy Assessment of Land UseLand Cover Classif.pdf:application/pdf},
}

@article{pflugmacher_mapping_2019,
	title = {Mapping pan-{European} land cover using {Landsat} spectral-temporal metrics and the {European} {LUCAS} survey},
	volume = {221},
	issn = {00344257},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0034425718305546},
	doi = {10.1016/j.rse.2018.12.001},
	language = {en},
	urldate = {2022-04-14},
	journal = {Remote Sensing of Environment},
	author = {Pflugmacher, Dirk and Rabe, Andreas and Peters, Mathias and Hostert, Patrick},
	month = feb,
	year = {2019},
	pages = {583--595},
	file = {Pflugmacher et al. - 2019 - Mapping pan-European land cover using Landsat spec.pdf:C\:\\Users\\Tomek\\Zotero\\storage\\BQVXWK3Z\\Pflugmacher et al. - 2019 - Mapping pan-European land cover using Landsat spec.pdf:application/pdf},
}

@article{meyer_machine_nodate,
	title = {Machine learning-based global maps of ecological variables and the challenge of assessing them},
	language = {en},
	author = {Meyer, Hanna},
	pages = {4},
	file = {Meyer - Machine learning-based global maps of ecological v.pdf:C\:\\Users\\Tomek\\Zotero\\storage\\VQRJ8792\\Meyer - Machine learning-based global maps of ecological v.pdf:application/pdf},
}

@misc{maksymiuk_landscape_2021,
	title = {Landscape of {R} packages for {eXplainable} {Artificial} {Intelligence}},
	url = {http://arxiv.org/abs/2009.13248},
	abstract = {The growing availability of data and computing power is fueling the development of predictive models. In order to ensure the safe and effective functioning of such models, we need methods for exploration, debugging, and validation. New methods and tools for this purpose are being developed within the eXplainable Artiﬁcial Intelligence (XAI) subdomain of machine learning. In this work, (1) we present the taxonomy of methods for model explanations, (2) we identify and compare 27 packages available in R to perform XAI analysis, (3) we present an example of an application of particular packages, (4) we acknowledge trends in recent developments. The article is primarily devoted to the tools available in R, but since it is easy to integrate the Python code, we will also show examples for the most popular libraries from Python.},
	language = {en},
	urldate = {2022-05-27},
	publisher = {arXiv},
	author = {Maksymiuk, Szymon and Gosiewska, Alicja and Biecek, Przemyslaw},
	month = mar,
	year = {2021},
	note = {Number: arXiv:2009.13248
arXiv:2009.13248 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: 20 pages},
	file = {Maksymiuk et al. - 2021 - Landscape of R packages for eXplainable Artificial.pdf:C\:\\Users\\Tomek\\Zotero\\storage\\B7JGW97X\\Maksymiuk et al. - 2021 - Landscape of R packages for eXplainable Artificial.pdf:application/pdf},
}

@article{dandrimont_harmonised_2020,
	title = {Harmonised {LUCAS} in-situ land cover and use database for field surveys from 2006 to 2018 in the {European} {Union}},
	volume = {7},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/s41597-020-00675-z},
	doi = {10.1038/s41597-020-00675-z},
	abstract = {The Data aggregation and Results sub-figures illustrate the work carried out in this study. The datasets collected during the five surveys (in 2006, 2009, 2012, 2015, 2018) are the main LUCAS products available (more in section Micro data collection and documentation (Protocol 1)). These datasets and their respective data documentation were used to create the multi-year harmonised database. The harmonisation process is described below and in Table 1. Associated with the summary Table 1, the Table 2 provides name changes, the Table 3 provides the new columns added, the Online-only Table 1 provides the missing column adding and the Online-only Table 2 provides the variable re-coding. The results are consolidated in one single consistent and legend-explicit table along with hard-coded links to the full resolution photos (stored on the GISCO, https://gisco-services.ec.europa. eu/lucas/photos/). The LUCAS primary data includes alpha-numerical variables and field photographs linked to the geo-referenced points.},
	language = {en},
	number = {1},
	urldate = {2022-11-13},
	journal = {Scientific Data},
	author = {d’Andrimont, Raphaël and Yordanov, Momchil and Martinez-Sanchez, Laura and Eiselt, Beatrice and Palmieri, Alessandra and Dominici, Paolo and Gallego, Javier and Reuter, Hannes Isaak and Joebges, Christian and Lemoine, Guido and van der Velde, Marijn},
	month = dec,
	year = {2020},
	pages = {352},
	file = {d’Andrimont et al. - 2020 - Harmonised LUCAS in-situ land cover and use databa.pdf:C\:\\Users\\Tomek\\Zotero\\storage\\HSBIDLYU\\d’Andrimont et al. - 2020 - Harmonised LUCAS in-situ land cover and use databa.pdf:application/pdf},
}

@article{sinha_improved_2015,
	title = {Improved {Land}-use/{Land}-cover classification of semi-arid deciduous forest landscape using thermal remote sensing},
	volume = {18},
	issn = {1110-9823},
	url = {https://www.sciencedirect.com/science/article/pii/S1110982315000551},
	doi = {10.1016/j.ejrs.2015.09.005},
	abstract = {Land Use Land Cover (LULC) change detection helps the policy makers to understand the environmental change dynamics to ensure sustainable development. Hence, LULC feature identification has emerged as an important research aspect and thus, a proper and accurate methodology for LULC classification is the need of time. In this study, Landsat-7 satellite data captured by Enhanced Thematic Mapper (ETM+) were used for LULC classification employing the maximum likelihood supervised classification (MLC) algorithm. The study targets the improvement of classification accuracy with the combined use of thermal and spectral information from satellite imagery. Land surface temperature (LST) is sensitive to land surface features and hence can be used to extract information on LULC features. The classification accuracy was found to improve on integrating the thermal information from the thermal band of Landsat ETM+ with spectral information. Two thermal vegetation indices, namely Thermal Integrated Vegetation Index (TLIVI) and Advanced Thermal Integrated Vegetation Index (ATLIVI), proposed in this study showed fairly good correlations (R2=0.65 and 0.7, respectively) with the derived surface temperature. These indices based on empirical parameterization of the relationship between surface temperature (Ts) and vegetation indices showed an increase of nearly 6\% in the overall accuracy for land-use/land-cover (LULC) classification in comparison to MLC algorithm using Standard False Colour Composite (FCC) satellite image of Landsat ETM+ as reference.},
	language = {en},
	number = {2},
	urldate = {2022-11-13},
	journal = {The Egyptian Journal of Remote Sensing and Space Science},
	author = {Sinha, Suman and Sharma, Laxmi Kant and Nathawat, Mahendra Singh},
	month = dec,
	year = {2015},
	keywords = {Classification, Land surface features, Land surface temperature (LST), Land Use Land Cover (LULC), Landsat ETM+, Thermal Vegetation Index (TVI)},
	pages = {217--233},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Tomek\\Zotero\\storage\\ATS4W7V4\\Sinha et al. - 2015 - Improved Land-useLand-cover classification of sem.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Tomek\\Zotero\\storage\\LXN46NB9\\S1110982315000551.html:text/html},
}

@article{fernandez-landa_operational_2016,
	title = {An {Operational} {Framework} for {Land} {Cover} {Classification} in the {Context} of {REDD}+ {Mechanisms}. {A} {Case} {Study} from {Costa} {Rica}},
	volume = {8},
	issn = {2072-4292},
	url = {http://www.mdpi.com/2072-4292/8/7/593},
	doi = {10.3390/rs8070593},
	abstract = {REDD+ implementation requires robust, consistent, accurate and transparent national land cover historical data and monitoring systems. Satellite imagery is the only data source with enough periodicity to provide consistent land cover information in a cost-effective way. The main aim of this paper is the creation of an operational framework for monitoring land cover dynamics based on Landsat imagery and open-source software. The methodology integrates the entire land cover and land cover change mapping processes to produce a consistent series of Land Cover maps. The consistency of the time series is achieved through the application of a single trained machine learning algorithm to radiometrically normalized imagery using iteratively re-weighted multivariate alteration detection (IR-MAD) across all dates of the historical period. As a result, seven individual Land Cover maps of Costa Rica were produced from 1985/1986 to 2013/2014. Post-classiﬁcation land cover change detection was performed to evaluate the land cover dynamics in Costa Rica. The validation of the land cover maps showed an overall accuracy of 87\% for the 2013/2014 map, 93\% for the 2000/2001 map and 89\% for the 1985/1986 map. Land cover changes between forest and non-forest classes were validated for the period between 2001 and 2011, obtaining an overall accuracy of 86\%. Forest age-classes were generated through a multi-temporal analysis of the maps. By linking deforestation dynamics with forest age, a more accurate discussion of the carbon emissions along the time series can be presented.},
	language = {en},
	number = {7},
	urldate = {2022-11-21},
	journal = {Remote Sensing},
	author = {Fernández-Landa, Alfredo and Algeet-Abarquero, Nur and Fernández-Moya, Jesús and Guillén-Climent, María and Pedroni, Lucio and García, Felipe and Espejo, Andrés and Villegas, Juan and Marchamalo, Miguel and Bonatti, Javier and Escamochero, Iñigo and Rodríguez-Noriega, Pablo and Papageorgiou, Stavros and Fernandes, Erick},
	month = jul,
	year = {2016},
	pages = {593},
	file = {Fernández-Landa et al. - 2016 - An Operational Framework for Land Cover Classifica.pdf:C\:\\Users\\Tomek\\Zotero\\storage\\WHLWPJLY\\Fernández-Landa et al. - 2016 - An Operational Framework for Land Cover Classifica.pdf:application/pdf},
}

@article{forkuor_landsat-8_2018,
	title = {Landsat-8 vs. {Sentinel}-2: examining the added value of sentinel-2’s red-edge bands to land-use and land-cover mapping in {Burkina} {Faso}},
	volume = {55},
	issn = {1548-1603, 1943-7226},
	shorttitle = {Landsat-8 vs. {Sentinel}-2},
	url = {https://www.tandfonline.com/doi/full/10.1080/15481603.2017.1370169},
	doi = {10.1080/15481603.2017.1370169},
	language = {en},
	number = {3},
	urldate = {2022-11-21},
	journal = {GIScience \& Remote Sensing},
	author = {Forkuor, Gerald and Dimobe, Kangbeni and Serme, Idriss and Tondoh, Jerome Ebagnerin},
	month = may,
	year = {2018},
	pages = {331--354},
	file = {Forkuor et al. - 2018 - Landsat-8 vs. Sentinel-2 examining the added valu.pdf:C\:\\Users\\Tomek\\Zotero\\storage\\ATYX4UP6\\Forkuor et al. - 2018 - Landsat-8 vs. Sentinel-2 examining the added valu.pdf:application/pdf},
}

@article{amini_urban_2022,
	title = {Urban {Land} {Use} and {Land} {Cover} {Change} {Analysis} {Using} {Random} {Forest} {Classification} of {Landsat} {Time} {Series}},
	volume = {14},
	issn = {2072-4292},
	url = {https://www.mdpi.com/2072-4292/14/11/2654},
	doi = {10.3390/rs14112654},
	abstract = {Efﬁcient implementation of remote sensing image classiﬁcation can facilitate the extraction of spatiotemporal information for land use and land cover (LULC) classiﬁcation. Mapping LULC change can pave the way to investigate the impacts of different socioeconomic and environmental factors on the Earth’s surface. This study presents an algorithm that uses Landsat time-series data to analyze LULC change. We applied the Random Forest (RF) classiﬁer, a robust classiﬁcation method, in the Google Earth Engine (GEE) using imagery from Landsat 5, 7, and 8 as inputs for the 1985 to 2019 period. We also explored the performance of the pan-sharpening algorithm on Landsat bands besides the impact of different image compositions to produce a high-quality LULC map. We used a statistical pan-sharpening algorithm to increase multispectral Landsat bands’ (Landsat 7–9) spatial resolution from 30 m to 15 m. In addition, we checked the impact of different image compositions based on several spectral indices and other auxiliary data such as digital elevation model (DEM) and land surface temperature (LST) on ﬁnal classiﬁcation accuracy based on several spectral indices and other auxiliary data on ﬁnal classiﬁcation accuracy. We compared the classiﬁcation result of our proposed method and the Copernicus Global Land Cover Layers (CGLCL) map to verify the algorithm. The results show that: (1) Using pan-sharpened top-of-atmosphere (TOA) Landsat products can produce more accurate results for classiﬁcation instead of using surface reﬂectance (SR) alone; (2) LST and DEM are essential features in classiﬁcation, and using them can increase ﬁnal accuracy; (3) the proposed algorithm produced higher accuracy (94.438\% overall accuracy (OA), 0.93 for Kappa, and 0.93 for F1-score) than CGLCL map (84.4\% OA, 0.79 for Kappa, and 0.50 for F1-score) in 2019; (4) the total agreement between the classiﬁcation results and the test data exceeds 90\% (93.37–97.6\%), 0.9 (0.91–0.96), and 0.85 (0.86–0.95) for OA, Kappa values, and F1-score, respectively, which is acceptable in both overall and Kappa accuracy. Moreover, we provide a code repository that allows classifying Landsat 4, 5, 7, and 8 within GEE. This method can be quickly and easily applied to other regions of interest for LULC mapping.},
	language = {en},
	number = {11},
	urldate = {2022-11-21},
	journal = {Remote Sensing},
	author = {Amini, Saeid and Saber, Mohsen and Rabiei-Dastjerdi, Hamidreza and Homayouni, Saeid},
	month = jun,
	year = {2022},
	pages = {2654},
	file = {Amini et al. - 2022 - Urban Land Use and Land Cover Change Analysis Usin.pdf:C\:\\Users\\Tomek\\Zotero\\storage\\22DEHZXH\\Amini et al. - 2022 - Urban Land Use and Land Cover Change Analysis Usin.pdf:application/pdf},
}

@book{oliver_buck_analysis_2015,
	title = {Analysis of the {LUCAS} nomenclature and proposal for adaptation of the nomenclature in view of its use by the {Copernicus} land monitoring services},
	url = {https://land.copernicus.eu/user-corner/technical-library/LUCAS_Copernicus_Report_v22.pdf},
	author = {Oliver Buck and Carsten Haub and Sascha Woditsch and Dirk Lindemann and Luca Kleinewillinghöfer, and Gerard Hazeu and Barbara Kosztra and Stefan Kleeschulte and Stephan Arnold and Martin Hölzl},
	month = nov,
	year = {2015},
}

@book{greenwell_hands-machine_nodate,
	title = {Hands-{On} {Machine} {Learning} with {R}},
	url = {https://bradleyboehmke.github.io/HOML/},
	abstract = {A Machine Learning Algorithmic Deep Dive Using R.},
	urldate = {2022-12-15},
	author = {Greenwell, Bradley Boehmke \& Brandon},
	file = {Snapshot:C\:\\Users\\Tomek\\Zotero\\storage\\VXS3KBGC\\HOML.html:text/html},
}

@article{mahesh_machine_2018,
	title = {Machine {Learning} {Algorithms} - {A} {Review}},
	volume = {9},
	abstract = {Machine learning (ML) is the scientific study of algorithms and statistical models that computer systems use to perform a specific task without being explicitly programmed. Learning algorithms in many applications that’s we make use of daily. Every time a web search engine like Google is used to search the internet, one of the reasons that work so well is because a learning algorithm that has learned how to rank web pages. These algorithms are used for various purposes like data mining, image processing, predictive analytics, etc. to name a few. The main advantage of using machine learning is that, once an algorithm learns what to do with data, it can do its work automatically. In this paper, a brief review and future prospect of the vast applications of machine learning algorithms has been made.},
	language = {en},
	number = {1},
	author = {Mahesh, Batta},
	year = {2018},
	file = {Mahesh - 2018 - Machine Learning Algorithms - A Review.pdf:C\:\\Users\\Tomek\\Zotero\\storage\\BCR6IBV3\\Mahesh - 2018 - Machine Learning Algorithms - A Review.pdf:application/pdf},
}

@article{sarker_machine_2021,
	title = {Machine {Learning}: {Algorithms}, {Real}-{World} {Applications} and {Research} {Directions}},
	volume = {2},
	issn = {2662-995X, 2661-8907},
	shorttitle = {Machine {Learning}},
	url = {https://link.springer.com/10.1007/s42979-021-00592-x},
	doi = {10.1007/s42979-021-00592-x},
	abstract = {In the current age of the Fourth Industrial Revolution (4IR or Industry 4.0), the digital world has a wealth of data, such as Internet of Things (IoT) data, cybersecurity data, mobile data, business data, social media data, health data, etc. To intelligently analyze these data and develop the corresponding smart and automated applications, the knowledge of artificial intelligence (AI), particularly, machine learning (ML) is the key. Various types of machine learning algorithms such as supervised, unsupervised, semi-supervised, and reinforcement learning exist in the area. Besides, the deep learning, which is part of a broader family of machine learning methods, can intelligently analyze the data on a large scale. In this paper, we present a comprehensive view on these machine learning algorithms that can be applied to enhance the intelligence and the capabilities of an application. Thus, this study’s key contribution is explaining the principles of different machine learning techniques and their applicability in various real-world application domains, such as cybersecurity systems, smart cities, healthcare, e-commerce, agriculture, and many more. We also highlight the challenges and potential research directions based on our study. Overall, this paper aims to serve as a reference point for both academia and industry professionals as well as for decision-makers in various real-world situations and application areas, particularly from the technical point of view.},
	language = {en},
	number = {3},
	urldate = {2022-12-15},
	journal = {SN Computer Science},
	author = {Sarker, Iqbal H.},
	month = may,
	year = {2021},
	pages = {160},
	file = {Sarker - 2021 - Machine Learning Algorithms, Real-World Applicati.pdf:C\:\\Users\\Tomek\\Zotero\\storage\\FYPK5NT7\\Sarker - 2021 - Machine Learning Algorithms, Real-World Applicati.pdf:application/pdf},
}

@article{sekulic_random_2020,
	title = {Random {Forest} {Spatial} {Interpolation}},
	volume = {12},
	issn = {2072-4292},
	url = {https://www.mdpi.com/2072-4292/12/10/1687},
	doi = {10.3390/rs12101687},
	abstract = {For many decades, kriging and deterministic interpolation techniques, such as inverse distance weighting and nearest neighbour interpolation, have been the most popular spatial interpolation techniques. Kriging with external drift and regression kriging have become basic techniques that beneﬁt both from spatial autocorrelation and covariate information. More recently, machine learning techniques, such as random forest and gradient boosting, have become increasingly popular and are now often used for spatial interpolation. Some attempts have been made to explicitly take the spatial component into account in machine learning, but so far, none of these approaches have taken the natural route of incorporating the nearest observations and their distances to the prediction location as covariates. In this research, we explored the value of including observations at the nearest locations and their distances from the prediction location by introducing Random Forest Spatial Interpolation (RFSI). We compared RFSI with deterministic interpolation methods, ordinary kriging, regression kriging, Random Forest and Random Forest for spatial prediction (RFsp) in three case studies. The ﬁrst case study made use of synthetic data, i.e., simulations from normally distributed stationary random ﬁelds with a known semivariogram, for which ordinary kriging is known to be optimal. The second and third case studies evaluated the performance of the various interpolation methods using daily precipitation data for the 2016–2018 period in Catalonia, Spain, and mean daily temperature for the year 2008 in Croatia. Results of the synthetic case study showed that RFSI outperformed most simple deterministic interpolation techniques and had similar performance as inverse distance weighting and RFsp. As expected, kriging was the most accurate technique in the synthetic case study. In the precipitation and temperature case studies, RFSI mostly outperformed regression kriging, inverse distance weighting, random forest, and RFsp. Moreover, RFSI was substantially faster than RFsp, particularly when the training dataset was large and high-resolution prediction maps were made.},
	language = {en},
	number = {10},
	urldate = {2022-12-20},
	journal = {Remote Sensing},
	author = {Sekulić, Aleksandar and Kilibarda, Milan and Heuvelink, Gerard B.M. and Nikolić, Mladen and Bajat, Branislav},
	month = may,
	year = {2020},
	pages = {1687},
	file = {Sekulić et al. - 2020 - Random Forest Spatial Interpolation.pdf:C\:\\Users\\Tomek\\Zotero\\storage\\7F4U9LQH\\Sekulić et al. - 2020 - Random Forest Spatial Interpolation.pdf:application/pdf},
}

@book{kuhn_applied_2013,
	address = {New York, NY},
	title = {Applied {Predictive} {Modeling}},
	isbn = {978-1-4614-6848-6 978-1-4614-6849-3},
	url = {http://link.springer.com/10.1007/978-1-4614-6849-3},
	language = {en},
	urldate = {2022-12-20},
	publisher = {Springer New York},
	author = {Kuhn, Max and Johnson, Kjell},
	year = {2013},
	doi = {10.1007/978-1-4614-6849-3},
	file = {Kuhn i Johnson - 2013 - Applied Predictive Modeling.pdf:C\:\\Users\\Tomek\\Zotero\\storage\\9Y8YGRG6\\Kuhn i Johnson - 2013 - Applied Predictive Modeling.pdf:application/pdf},
}

@article{qi_random_2012,
	title = {Random {Forest} for {Bioinformatics}},
	language = {en},
	author = {Qi, Yanjun},
	month = jan,
	year = {2012},
	file = {Qi - Random Forest for Bioinformatics.pdf:C\:\\Users\\Tomek\\Zotero\\storage\\WS9D8PL3\\Qi - Random Forest for Bioinformatics.pdf:application/pdf},
}

@article{schonlau_random_2020,
	title = {The random forest algorithm for statistical learning},
	volume = {20},
	issn = {1536-867X, 1536-8734},
	url = {http://journals.sagepub.com/doi/10.1177/1536867X20909688},
	doi = {10.1177/1536867X20909688},
	abstract = {Random forests (Breiman, 2001, Machine Learning 45: 5–32) is a statistical- or machine-learning algorithm for prediction. In this article, we introduce a corresponding new command, rforest. We overview the random forest algorithm and illustrate its use with two examples: The ﬁrst example is a classiﬁcation problem that predicts whether a credit card holder will default on his or her debt. The second example is a regression problem that predicts the logscaled number of shares of online news articles. We conclude with a discussion that summarizes key points demonstrated in the examples.},
	language = {en},
	number = {1},
	urldate = {2022-12-20},
	journal = {The Stata Journal: Promoting communications on statistics and Stata},
	author = {Schonlau, Matthias and Zou, Rosie Yuyan},
	month = mar,
	year = {2020},
	pages = {3--29},
	file = {Schonlau i Zou - 2020 - The random forest algorithm for statistical learni.pdf:C\:\\Users\\Tomek\\Zotero\\storage\\DWY52MFL\\Schonlau i Zou - 2020 - The random forest algorithm for statistical learni.pdf:application/pdf},
}

@misc{qgis_development_team_qgis_2009,
	title = {{QGIS} {Geographic} {Information} {System}},
	url = {https://www.qgis.org},
	publisher = {QGIS Association},
	author = {{QGIS Development Team}},
	year = {2009},
}

@misc{rstudio_team_rstudio_2020,
	address = {Boston, MA},
	title = {{RStudio}: {Integrated} {Development} {Environment} for {R}},
	url = {http://www.rstudio.com/},
	publisher = {RStudio, PBC.},
	author = {{RStudio Team}},
	year = {2020},
}

@article{breiman_random_2001,
	title = {Random {Forests}},
	volume = {45},
	issn = {1573-0565},
	url = {https://doi.org/10.1023/A:1010933404324},
	doi = {10.1023/A:1010933404324},
	abstract = {Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund \& R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148–156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.},
	number = {1},
	journal = {Machine Learning},
	author = {Breiman, Leo},
	month = oct,
	year = {2001},
	pages = {5--32},
	file = {A1010933404324.pdf:C\:\\Users\\Tomek\\Zotero\\storage\\SGZ3IPSX\\A1010933404324.pdf:application/pdf},
}

@article{xie_evaluation_2018,
	title = {Evaluation of machine learning methods for formation lithology identification: {A} comparison of tuning processes and model performances},
	volume = {160},
	issn = {0920-4105},
	shorttitle = {Evaluation of machine learning methods for formation lithology identification},
	url = {https://www.sciencedirect.com/science/article/pii/S0920410517308094},
	doi = {10.1016/j.petrol.2017.10.028},
	abstract = {Identification of underground formation lithology from well log data is an important task in petroleum exploration and engineering. Recently, several computational algorithms have been used for lithology identification to improve the prediction accuracy. In this paper, we evaluate five typical machine learning methods, namely the Naïve Bayes, Support Vector Machine, Artificial Neural Network, Random Forest and Gradient Tree Boosting, for formation lithology identification using data from the Daniudui gas field and the Hangjinqi gas field. The input to each model consists of features selected from different well log data samples. To determine the best model to classify the lithology type, this study used validation curve to determine the parameter search range and adopted the hyper-parameter optimization method to obtain the best parameter set for each model. The performance of each classifier is also evaluated using 5-fold cross validation. The results suggest that ensemble methods are good algorithm choices for supervised classification of lithology using well log data. The Gradient Tree Boosting classifier is robust to overfitting because it grows trees sequentially by adjusting the weight of the training data distribution to minimize a loss function. The random forest classifier is also a suitable option. An evaluation matrix showed that the Gradient Tree Boosting and Random Forest classifiers have lower prediction errors compared with the other three models. Although all the models have difficulties in distinguishing sandstone classes, the Gradient Tree Boosting performs well on this task compared with the other four methods. Moreover, the classification accuracy is remarkably similar across the lithology classes for both the Random Forest and Gradient Tree Boosting models.},
	language = {en},
	urldate = {2023-01-02},
	journal = {Journal of Petroleum Science and Engineering},
	author = {Xie, Yunxin and Zhu, Chenyang and Zhou, Wen and Li, Zhongdong and Liu, Xuan and Tu, Mei},
	month = jan,
	year = {2018},
	keywords = {Gradient boosting, Lithology identification, Supervised learning, Tuning parameter},
	pages = {182--193},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Tomek\\Zotero\\storage\\UDNQH9GR\\Xie et al. - 2018 - Evaluation of machine learning methods for formati.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Tomek\\Zotero\\storage\\GD3YC493\\S0920410517308094.html:text/html},
}

@article{seyedzadeh_tuning_2019,
	title = {Tuning machine learning models for prediction of building energy loads},
	volume = {47},
	issn = {22106707},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2210670718318511},
	doi = {10.1016/j.scs.2019.101484},
	abstract = {There have been numerous simulation tools utilised for calculating building energy loads for eﬃcient design and retroﬁtting. However, these tools entail a great deal of computational cost and prior knowledge to work with. Machine Learning (ML) techniques can contribute to bridging this gap by taking advantage of existing historical data for forecasting new samples and lead to informed decisions. This study investigated the accuracy of most popular ML models in the prediction of buildings heating and cooling loads carrying out speciﬁc tuning for each ML model and using two simulated building energy data generated in EnergyPlus and Ecotect and compared the results. The study used a grid-search coupled with cross-validation method to examine the combinations of model parameters. Furthermore, sensitivity analysis techniques were used to evaluate the importance of input variables on the performance of ML models. The accuracy and time complexity of models in predicting heating and cooling loads are demonstrated. Comparing the accuracy of the tuned models with the original research works reveals the signiﬁcant role of model optimisation. The outcomes of the sensitivity analysis are demonstrated as relative importance which resulted in the identiﬁcation of unimportant variables and faster model ﬁtting.},
	language = {en},
	urldate = {2023-01-02},
	journal = {Sustainable Cities and Society},
	author = {Seyedzadeh, Saleh and Pour Rahimian, Farzad and Rastogi, Parag and Glesk, Ivan},
	month = may,
	year = {2019},
	pages = {101484},
	file = {Seyedzadeh et al. - 2019 - Tuning machine learning models for prediction of b.pdf:C\:\\Users\\Tomek\\Zotero\\storage\\ANZ4CR65\\Seyedzadeh et al. - 2019 - Tuning machine learning models for prediction of b.pdf:application/pdf},
}

@article{yang_hyperparameter_2020,
	title = {On {Hyperparameter} {Optimization} of {Machine} {Learning} {Algorithms}: {Theory} and {Practice}},
	volume = {415},
	issn = {09252312},
	shorttitle = {On {Hyperparameter} {Optimization} of {Machine} {Learning} {Algorithms}},
	url = {http://arxiv.org/abs/2007.15745},
	doi = {10.1016/j.neucom.2020.07.061},
	abstract = {Machine learning algorithms have been used widely in various applications and areas. To fit a machine learning model into different problems, its hyper-parameters must be tuned. Selecting the best hyper-parameter configuration for machine learning models has a direct impact on the model's performance. It often requires deep knowledge of machine learning algorithms and appropriate hyper-parameter optimization techniques. Although several automatic optimization techniques exist, they have different strengths and drawbacks when applied to different types of problems. In this paper, optimizing the hyper-parameters of common machine learning models is studied. We introduce several state-of-the-art optimization techniques and discuss how to apply them to machine learning algorithms. Many available libraries and frameworks developed for hyper-parameter optimization problems are provided, and some open challenges of hyper-parameter optimization research are also discussed in this paper. Moreover, experiments are conducted on benchmark datasets to compare the performance of different optimization methods and provide practical examples of hyper-parameter optimization. This survey paper will help industrial users, data analysts, and researchers to better develop machine learning models by identifying the proper hyper-parameter configurations effectively.},
	language = {en},
	urldate = {2023-01-02},
	journal = {Neurocomputing},
	author = {Yang, Li and Shami, Abdallah},
	month = nov,
	year = {2020},
	note = {arXiv:2007.15745 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, 68T01, 90C31, C.2.0, I.2.0, I.2.2},
	pages = {295--316},
	annote = {Comment: Published in Neurocomputing (Elsevier's journal, Q1, IF: 5.779). Tutorial code has got 1000+ stars. Github link: https://github.com/LiYangHart/Hyperparameter-Optimization-of-Machine-Learning-Algorithms},
	file = {Yang i Shami - 2020 - On Hyperparameter Optimization of Machine Learning.pdf:C\:\\Users\\Tomek\\Zotero\\storage\\G7FGXWRL\\Yang i Shami - 2020 - On Hyperparameter Optimization of Machine Learning.pdf:application/pdf},
}

@book{hutter_automated_2019,
	address = {Cham},
	series = {The {Springer} {Series} on {Challenges} in {Machine} {Learning}},
	title = {Automated {Machine} {Learning}: {Methods}, {Systems}, {Challenges}},
	isbn = {978-3-030-05317-8 978-3-030-05318-5},
	shorttitle = {Automated {Machine} {Learning}},
	url = {http://link.springer.com/10.1007/978-3-030-05318-5},
	language = {en},
	urldate = {2023-01-02},
	publisher = {Springer International Publishing},
	editor = {Hutter, Frank and Kotthoff, Lars and Vanschoren, Joaquin},
	year = {2019},
	doi = {10.1007/978-3-030-05318-5},
	file = {Hutter et al. - 2019 - Automated Machine Learning Methods, Systems, Chal.pdf:C\:\\Users\\Tomek\\Zotero\\storage\\IKD9MJ49\\Hutter et al. - 2019 - Automated Machine Learning Methods, Systems, Chal.pdf:application/pdf},
}

@article{jiao_performance_2016,
	title = {Performance measures in evaluating machine learning based bioinformatics predictors for classifications},
	volume = {4},
	issn = {2095-4689, 2095-4697},
	url = {https://journal.hep.com.cn/qb/EN/10.1007/s40484-016-0081-2},
	doi = {10.1007/s40484-016-0081-2},
	abstract = {Background: Many existing bioinformatics predictors are based on machine learning technology. When applying these predictors in practical studies, their predictive performances should be well understood. Different performance measures are applied in various studies as well as different evaluation methods. Even for the same performance measure, different terms, nomenclatures or notations may appear in different context.
Results: We carried out a review on the most commonly used performance measures and the evaluation methods for bioinformatics predictors.
Conclusions: It is important in bioinformatics to correctly understand and interpret the performance, as it is the key to rigorously compare performances of different predictors and to choose the right predictor.},
	language = {en},
	number = {4},
	urldate = {2023-01-03},
	journal = {Quantitative Biology},
	author = {Jiao, Yasen and Du, Pufeng},
	month = dec,
	year = {2016},
	pages = {320--330},
	file = {Jiao i Du - 2016 - Performance measures in evaluating machine learnin.pdf:C\:\\Users\\Tomek\\Zotero\\storage\\KLNZN3AQ\\Jiao i Du - 2016 - Performance measures in evaluating machine learnin.pdf:application/pdf},
}

@article{sohil_introduction_2022,
	title = {An introduction to statistical learning with applications in {R}: by {Gareth} {James}, {Daniela} {Witten}, {Trevor} {Hastie}, and {Robert} {Tibshirani}, {New} {York}, {Springer} {Science} and {Business} {Media}, 2013, \$41.98, {eISBN}: 978-1-4614-7137-7},
	volume = {6},
	issn = {2475-4269, 2475-4277},
	shorttitle = {An introduction to statistical learning with applications in {R}},
	url = {https://www.tandfonline.com/doi/full/10.1080/24754269.2021.1980261},
	doi = {10.1080/24754269.2021.1980261},
	language = {en},
	number = {1},
	urldate = {2023-01-03},
	journal = {Statistical Theory and Related Fields},
	author = {Sohil, Fariha and Sohali, Muhammad Umair and Shabbir, Javid},
	month = jan,
	year = {2022},
	pages = {87--87},
	file = {Sohil et al. - 2022 - An introduction to statistical learning with appli.pdf:C\:\\Users\\Tomek\\Zotero\\storage\\UVRZYD64\\Sohil et al. - 2022 - An introduction to statistical learning with appli.pdf:application/pdf},
}

@book{lovelace_geocomputation_2019,
	title = {Geocomputation with {R}},
	isbn = {1-138-30451-4},
	abstract = {Book on geographic data with R.},
	publisher = {CRC Press},
	author = {Lovelace, Robin and Nowosad, Jakub and Muenchow, Jannes},
	year = {2019},
}

@article{schratz_hyperparameter_2019,
	title = {Hyperparameter tuning and performance assessment of statistical and machine-learning algorithms using spatial data},
	volume = {406},
	issn = {03043800},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0304380019302145},
	doi = {10.1016/j.ecolmodel.2019.06.002},
	abstract = {While the application of machine-learning algorithms has been highly simplified in the last years due to their well-documented integration in commonly used statistical programming languages (such as R or Python), there are several practical challenges in the field of ecological modeling related to unbiased performance estimation. One is the influence of spatial autocorrelation in both hyperparameter tuning and performance estimation. Grouped cross-validation strategies have been proposed in recent years in environmental as well as medical contexts to reduce bias in predictive performance. In this study we show the effects of spatial autocorrelation on hyperparameter tuning and performance estimation by comparing several widely used machine-learning algorithms such as boosted regression trees (BRT), k-nearest neighbor (KNN), random forest (RF) and support vector machine (SVM) with traditional parametric algorithms such as logistic regression (GLM) and semi-parametric ones like generalized additive models (GAM) in terms of predictive performance. Spatial and non-spatial crossvalidation methods were used to evaluate model performances aiming to obtain bias-reduced performance estimates. A detailed analysis on the sensitivity of hyperparameter tuning when using different resampling methods (spatial/non-spatial) was performed. As a case study the spatial distribution of forest disease (Diplodia sapinea) in the Basque Country (Spain) was investigated using common environmental variables such as temperature, precipitation, soil and lithology as predictors. Random Forest (mean Brier score estimate of 0.166) outperformed all other methods with regard to predictive accuracy. Though the sensitivity to hyperparameter tuning differed between the ML algorithms, there were in most cases no substantial differences between spatial and non-spatial partitioning for hyperparameter tuning. However, spatial hyperparameter tuning maintains consistency with spatial estimation of classifier performance and should be favored over non-spatial hyperparameter optimization. High performance differences (up to 47\%) between the bias-reduced (spatial crossvalidation) and overoptimistic (non-spatial cross-validation) cross-validation settings showed the high need to account for the influence of spatial autocorrelation. Overoptimistic performance estimates may lead to false actions in ecological decision making based on biased model predictions.},
	language = {en},
	urldate = {2023-01-03},
	journal = {Ecological Modelling},
	author = {Schratz, Patrick and Muenchow, Jannes and Iturritxa, Eugenia and Richter, Jakob and Brenning, Alexander},
	month = aug,
	year = {2019},
	pages = {109--120},
	file = {Schratz et al. - 2019 - Hyperparameter tuning and performance assessment o.pdf:C\:\\Users\\Tomek\\Zotero\\storage\\GK4ZUEI2\\Schratz et al. - 2019 - Hyperparameter tuning and performance assessment o.pdf:application/pdf},
}

@inproceedings{brenning_spatial_2012,
	address = {Munich, Germany},
	title = {Spatial cross-validation and bootstrap for the assessment of prediction rules in remote sensing: {The} {R} package sperrorest},
	isbn = {978-1-4673-1159-5 978-1-4673-1160-1 978-1-4673-1158-8},
	shorttitle = {Spatial cross-validation and bootstrap for the assessment of prediction rules in remote sensing},
	url = {http://ieeexplore.ieee.org/document/6352393/},
	doi = {10.1109/IGARSS.2012.6352393},
	abstract = {Novel computational and statistical prediction methods such as the support vector machine are becoming increasingly popular in remote-sensing applications and need to be compared to more traditional approaches like maximum-likelihood classiﬁcation. However, the accuracy assessment of such predictive models in a spatial context needs to account for the presence of spatial autocorrelation in geospatial data by using spatial cross-validation and bootstrap strategies instead of their now more widely used non-spatial equivalent. These spatial resampling-based estimation procedures were therefore implemented in a new package ‘sperrorest’ for the opensource statistical data analysis software R. This package is introduced using the example of the detection of rock-glacier ﬂow structures from IKONOS-derived Gabor texture features and terrain attribute data.},
	language = {en},
	urldate = {2023-01-03},
	booktitle = {2012 {IEEE} {International} {Geoscience} and {Remote} {Sensing} {Symposium}},
	publisher = {IEEE},
	author = {Brenning, Alexander},
	month = jul,
	year = {2012},
	pages = {5372--5375},
	file = {Brenning - 2012 - Spatial cross-validation and bootstrap for the ass.pdf:C\:\\Users\\Tomek\\Zotero\\storage\\N3T8TPPN\\Brenning - 2012 - Spatial cross-validation and bootstrap for the ass.pdf:application/pdf},
}

@article{tobler_computer_1970,
	title = {A {Computer} {Movie} {Simulating} {Urban} {Growth} in the {Detroit} {Region}},
	volume = {46},
	issn = {00130095},
	url = {https://www.jstor.org/stable/143141?origin=crossref},
	doi = {10.2307/143141},
	language = {en},
	urldate = {2023-01-04},
	journal = {Economic Geography},
	author = {Tobler, W. R.},
	month = jun,
	year = {1970},
	pages = {234},
	file = {Tobler - 1970 - A Computer Movie Simulating Urban Growth in the De.pdf:C\:\\Users\\Tomek\\Zotero\\storage\\M7P8NGEH\\Tobler - 1970 - A Computer Movie Simulating Urban Growth in the De.pdf:application/pdf},
}

@book{biecek_explanatory_2021,
	title = {Explanatory {Model} {Analysis}},
	isbn = {978-0-367-13559-1},
	url = {https://pbiecek.github.io/ema/},
	publisher = {Chapman and Hall/CRC, New York},
	author = {Biecek, Przemyslaw and Burzykowski, Tomasz},
	year = {2021},
}

@inproceedings{mannor_cross_2005,
	address = {Bonn, Germany},
	title = {The cross entropy method for classification},
	isbn = {978-1-59593-180-1},
	url = {http://portal.acm.org/citation.cfm?doid=1102351.1102422},
	doi = {10.1145/1102351.1102422},
	abstract = {We consider support vector machines for binary classiﬁcation. As opposed to most approaches we use the number of support vectors (the “L0 norm”) as a regularizing term instead of the L1 or L2 norms. In order to solve the optimization problem we use the cross entropy method to search over the possible sets of support vectors. The algorithm consists of solving a sequence of eﬃcient linear programs. We report experiments where our method produces generalization errors that are similar to support vector machines, while using a considerably smaller number of support vectors.},
	language = {en},
	urldate = {2023-01-09},
	booktitle = {Proceedings of the 22nd international conference on {Machine} learning  - {ICML} '05},
	publisher = {ACM Press},
	author = {Mannor, Shie and Peleg, Dori and Rubinstein, Reuven},
	year = {2005},
	pages = {561--568},
	file = {Mannor et al. - 2005 - The cross entropy method for classification.pdf:C\:\\Users\\Tomek\\Zotero\\storage\\6KMJGG8W\\Mannor et al. - 2005 - The cross entropy method for classification.pdf:application/pdf},
}

@article{strumbelj_efficient_2010,
	title = {An {Efficient} {Explanation} of {Individual} {Classifications} using {Game} {Theory}},
	abstract = {We present a general method for explaining individual predictions of classiﬁcation models. The method is based on fundamental concepts from coalitional game theory and predictions are explained with contributions of individual feature values. We overcome the method’s initial exponential time complexity with a sampling-based approximation. In the experimental part of the paper we use the developed method on models generated by several well-known machine learning algorithms on both synthetic and real-world data sets. The results demonstrate that the method is efﬁcient and that the explanations are intuitive and useful.},
	language = {en},
	author = {Strumbelj, Erik and Kononenko, Igor},
	year = {2010},
	file = {Strumbelj i Kononenko - An Efficient Explanation of Individual Classificat.pdf:C\:\\Users\\Tomek\\Zotero\\storage\\HRN9BXU2\\Strumbelj i Kononenko - An Efficient Explanation of Individual Classificat.pdf:application/pdf},
}

@article{strumbelj_explaining_2014,
	title = {Explaining prediction models and individual predictions with feature contributions},
	volume = {41},
	issn = {0219-1377, 0219-3116},
	url = {http://link.springer.com/10.1007/s10115-013-0679-x},
	doi = {10.1007/s10115-013-0679-x},
	abstract = {We present a sensitivity analysis-based method for explaining prediction models that can be applied to any type of classiﬁcation or regression model. Its advantage over existing general methods is that all subsets of input features are perturbed, so interactions and redundancies between features are taken into account. Furthermore, when explaining an additive model, the method is equivalent to commonly used additive model-speciﬁc methods. We illustrate the method’s usefulness with examples from artiﬁcial and real-world data sets and an empirical analysis of running times. Results from a controlled experiment with 122 participants suggest that the method’s explanations improved the participants’ understanding of the model.},
	language = {en},
	number = {3},
	urldate = {2023-01-09},
	journal = {Knowledge and Information Systems},
	author = {Štrumbelj, Erik and Kononenko, Igor},
	month = dec,
	year = {2014},
	pages = {647--665},
	file = {Štrumbelj i Kononenko - 2014 - Explaining prediction models and individual predic.pdf:C\:\\Users\\Tomek\\Zotero\\storage\\YS5NYFJ4\\Štrumbelj i Kononenko - 2014 - Explaining prediction models and individual predic.pdf:application/pdf},
}

@incollection{shapley_value_1953,
	title = {A {VALUE} {FOR} n-{PERSON} {GAMES}},
	isbn = {978-0-691-07935-6},
	url = {http://www.jstor.org/stable/j.ctt1b9x1zv.24},
	abstract = {At the foundation of the theory of games is the assumption that the players of a game can evaluate, in their utility scales, every "prospect" that might arise as a result of a play. In attempting to apply the theory to any field, one would normally expect to be permitted to include, in the class of "prospects," the prospect of having to play a game. The possibility of evaluating games is therefore of critical importance. So long as the theory is unable to assign values to the games typically found in application, only relatively simple situations -- where games do},
	urldate = {2023-01-09},
	booktitle = {Contributions to the {Theory} of {Games} ({AM}-28), {Volume} {II}},
	publisher = {Princeton University Press},
	author = {Shapley, L. S. and ARROW, K. J. and BARANKIN, E. W. and BLACKWELL, D. and BOTT, R. and DALKEY, N. and DRESHER, M. and GALE, D. and GILLIES, D. B. and GLICKSBERG, I. and GROSS, O. and KARLIN, S. and KUHN, H. W. and MAYBERRY, J. P. and MILNOR, J. W. and MOTZKIN, T. S. and VON NEUMANN, J. and RAIFFA, H. and SHAPLEY, L. S. and SHIFFMAN, M. and STEWART, F. M. and THOMPSON, G. L. and THRALL, R. M.},
	editor = {Kuhn, H. W. and Tucker, A. W.},
	year = {1953},
	pages = {307--318},
}
